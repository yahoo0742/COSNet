"train":
    "pretrained_models":
        "deep_labv3_davis":
            "model": "deep_labv3"
            "dataset": "davis"
            "file": "./pretrained/deep_labv3/deeplab_davis_12_0.pth" #"./pretrained/davis_480x854_Aug16.pth"
        
        "resnet101_cityscapes":
            "model": "resnet101"
            "dataset": "cityscapes"
            "path": ""

    "dataset":
        "davis":
            "img_path": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/JPEGImages/480p/"
            "annotation_path": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/Annotations/480p/"
            "subset_file": "./train_seqs.txt"
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/"
            "batch_size": 4 #10 # 1 card: 5 2 cards: 10 Number of images sent to the network in one step 16 on paper
            "max_epoches": 30 #60 # 1 card: 15 2 cards: 15 epoches equal to 30k iterations max iterations= maxEpoches*len(train_aug)/batch_size_per_gpu')
            "ignore_label": 255 #The index of the label to ignore during the training
            "input_size": '854,480' #'854480' #Comma-separated string with height and width of images
            "output_HW": '480,854'
            "num_classes": 2      #Number of classes to predict (including background)
            "img_mean": [104.00698793, 116.66876762, 122.67891434] ## saving model file and log record during the process of training
            "pretrained_model": "deep_labv3_davis" #Where restore model pretrained on other dataset such as COCO
            "snapshot_output_path": "./snapshots/davis_480x854s/"          #Where to save snapshots of the model
            "checkpoint_file": "./snapshots/davis/co_attention_davis_124.pth" #checkpoint log file helping recovering training
            "saliency_datasets":
                - "DUTS-TR"
                - "MSRA10K_Imgs_GT"
        "hzfurgbd":
            "subset_file": "./train_seqs.txt"
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset/"
            "batch_size": 4 # 1 card: 5 2 cards: 10 Number of images sent to the network in one step 16 on paper
            "max_epoches": 30 # 1 card: 15 2 cards: 15 epoches equal to 30k iterations max iterations= maxEpoches*len(train_aug)/batch_size_per_gpu')
            "ignore_label": 255 #The index of the label to ignore during the training
            "input_size": '640,480' #'640,480'  #Comma-separated string with height and width of images
            "output_HW": '480,640'
            "num_classes": 2      #Number of classes to predict (including background)
            "img_mean": [104.00698793, 116.66876762, 122.67891434] ## saving model file and log record during the process of training
            "pretrained_model": "deep_labv3_davis" #Where restore model pretrained on other dataset such as COCO
            "snapshot_output_path": "./snapshots/hzfurgbd_iteration/"          #Where to save snapshots of the model
            "checkpoint_file": "./snapshots/hzfurgbd/co_attention_hzfurgbd.pth" #checkpoint log file helping recovering training


    "saliency_dataset":
        "root_path": "/vol/graphics-solar/fengwenb/vos/saliency_dataset/"
        "datasets":
            "DUTS-TR":
                "images": "./DUTS-TR/Imgs/"
                "masks": "./DUTS-TR/Masks/"
            
            "MSRA10K_Imgs_GT":
                "images": "./MSRA10K_Imgs_GT/Imgs/"
                "masks": "./MSRA10K_Imgs_GT/Masks/"


"test":
    "model":
        "original_coattention_rgb":
            "pretrained_params": "./pretrained/co_attention.pth" # './pretrained/davis_480x854_Aug16.pth'
        "original_coattention_rgb_retrained":
            "pretrained_params": "./pretrained/davis_480x854_Aug16.pth"
        "refactored_coattention_rgb":
            "pretrained_params": "./snapshots/davis_480x854s/co_attention_davis_29.pth"
        "added_depth_rgbd":
            "pretrained_params": "./snapshots/hzfurgbd_iteration/H480W640/20210816_2309/snapshot_hzfurgbd_29.pth" #'./snapshots/hzfurgbd_iteration/H480W640/20210816_2309/snapshot_hzfurgbd_29.pth' #'./snapshots/hzfurgbd_iteration/H120W160/20210814_2145/co_attention_rgbd_hzfurgbd_29.pth' # './snapshots/hzfurgbd_iteration/co_attention_rgbd_hzfurgbd_29.pth' # './snapshots/co_attention_rgbd_hzfurgbd_29.pth' #'./your_path.pth' #resnet50-19c8e357.pth''/home/xiankai/PSPNet_PyTorch/snapshots/davis/psp_davis_0.pth'
        "concatenated_depth_rgbd":
            "pretrained_params": "./snapshots/hzfurgbd/coc/H480W640/20210822_113019/snapshot_hzfurgbd_29.pth" #20210822_164649
        "concatenated_depth_rgbd2":
            "pretrained_params": "./snapshots/hzfurgbd/coc/H480W640/20210822_113019/snapshot_hzfurgbd_29.pth" #20210822_164649
    "dataset":
        "davis":
            "model":
            "subset_file": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/ImageSets/480p/val.txt"
            "path": ""
            "output_WH": ""
        "hzfurgb":
            "model":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset"
            "output_WH": "640,480"
            "image_HW_4_model": "480, 640"
            "sample_range": 1
        "hzfurgbd":
            "model":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset"
            "output_WH": "640,480"
            "image_HW_4_model": "480, 640"
            "sample_range": 1
    
    

