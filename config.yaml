'pretrained_params':
    "deep_labv3_davis":
        "initial_params": ""
        "by_model": "deep_labv3"
        "file_of_output_params": "./pretrained/deep_labv3/deeplab_davis_12_0.pth"
    "original_coattention_rgb":
        "initial_params": "deep_labv3_davis"
        "by_model": "original_coattention_rgb"
        "file_of_output_params": "./pretrained/co_attention.pth" #"./pretrained/davis_480x854_Aug16.pth"
    "original_coattention_rgb_retrained":
        "initial_params": "deep_labv3_davis"
        "by_model": "original_coattention_rgb"
        "dataset": ["davis", "DUTS-TR", "MSRA10K_Imgs_GT"]
        "file_of_output_params": ""
    "co_attention_refactored":
        "initial_params": "deep_labv3_davis"
        "by_model": "refactored_coattention_rgb"
        "dataset": ["davis", "DUTS-TR", "MSRA10K_Imgs_GT"]
        "file_of_output_params": ""
    "resnet_aspp_add_hzfurgbd":
        "initial_params": "deep_labv3_davis"
        "by_model": "resnet_aspp_add"
        "dataset": ["hzfurgbd"]
        "file_of_output_params": ""
    "resnet101_cityscapes":
        "model": "resnet101"
        "dataset": "cityscapes"
        "path": ""

"train":
    "model":
        "original_coattention_rgb_retrained":
            "initial_params": "./pretrained/deep_labv3/deeplab_davis_12_0.pth"
        "co_attention_refactored":
            "initial_params": "./pretrained/deep_labv3/deeplab_davis_12_0.pth"
        "resnet_aspp_add":
            "initial_params": "./pretrained/co_attention.pth" #"./pretrained/davis_480x854_Aug16.pth"
    "dataset":
        "davis":
            "img_path": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/JPEGImages/480p/"
            "annotation_path": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/Annotations/480p/"
            "subset_file": "./train_seqs.txt"
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/"
            "batch_size": 4 #10 # 1 card: 5 2 cards: 10 Number of images sent to the network in one step 16 on paper
            "max_epoches": 30 #60 # 1 card: 15 2 cards: 15 epoches equal to 30k iterations max iterations= maxEpoches*len(train_aug)/batch_size_per_gpu')
            "ignore_label": 255 #The index of the label to ignore during the training
            "input_size": '854,480' #'854480' #Comma-separated string with height and width of images
            "output_HW": '480,854'
            "num_classes": 2      #Number of classes to predict (including background)
            "img_mean": [104.00698793, 116.66876762, 122.67891434] ## saving model file and log record during the process of training
            "pretrained_model": "deep_labv3_davis" #Where restore model pretrained on other dataset such as COCO
            "snapshot_output_path": "./snapshots/davis_480x854s/"          #Where to save snapshots of the model
            "checkpoint_file": "./snapshots/davis/co_attention_davis_124.pth" #checkpoint log file helping recovering training
            "saliency_datasets":
                - "DUTS-TR"
                - "MSRA10K_Imgs_GT"
        "hzfurgbd":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset/"
            "batch_size": 4 # 1 card: 5 2 cards: 10 Number of images sent to the network in one step 16 on paper
            "max_epoches": 50 # 1 card: 15 2 cards: 15 epoches equal to 30k iterations max iterations= maxEpoches*len(train_aug)/batch_size_per_gpu')
            "ignore_label": 255 #The index of the label to ignore during the training
            "input_size": '640,480' #'640,480'  #Comma-separated string with height and width of images
            "output_HW": '480,640'
            "num_classes": 2      #Number of classes to predict (including background)
            "img_mean": [104.00698793, 116.66876762, 122.67891434] ## saving model file and log record during the process of training
            "pretrained_model": "deep_labv3_davis" #Where restore model pretrained on other dataset such as COCO
            "snapshot_output_path": "./snapshots/hzfurgbd_iteration/"          #Where to save snapshots of the model
            "checkpoint_file": "./snapshots/hzfurgbd/co_attention_hzfurgbd.pth" #checkpoint log file helping recovering training
            "subset":
                "child_no1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png"]
                "dog_no_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png"]
                "toy_wg_occ": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png","46_obj_1.png","51_obj_1.png"]
                "tracking4": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png"]
                "zcup_move_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png"]
        "sbmrgbd":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/sbm-rgbd/AllSequences/"
            "batch_size": 4 # 1 card: 5 2 cards: 10 Number of images sent to the network in one step 16 on paper
            "max_epoches": 50 # 1 card: 15 2 cards: 15 epoches equal to 30k iterations max iterations= maxEpoches*len(train_aug)/batch_size_per_gpu')
            "ignore_label": 255 #The index of the label to ignore during the training
            "input_size": '640,480' #'640,480'  #Comma-separated string with height and width of images
            "output_HW": '480,640'
            "num_classes": 2      #Number of classes to predict (including background)
            "img_mean": [104.00698793, 116.66876762, 122.67891434] ## saving model file and log record during the process of training
            "pretrained_model": "deep_labv3_davis" #Where restore model pretrained on other dataset such as COCO
            "snapshot_output_path": "./snapshots/sbmrgbd/"          #Where to save snapshots of the model
            "checkpoint_file": "./snapshots/sbmrgbd/co_attention_sbmrgbd.pth" #checkpoint log file helping recovering training
            "subset": None

    "saliency_dataset":
        "root_path": "/vol/graphics-solar/fengwenb/vos/saliency_dataset/"
        "datasets":
            "DUTS-TR":
                "images": "./DUTS-TR/Imgs/"
                "masks": "./DUTS-TR/Masks/"
            
            "MSRA10K_Imgs_GT":
                "images": "./MSRA10K_Imgs_GT/Imgs/"
                "masks": "./MSRA10K_Imgs_GT/Masks/"


"test":
    "model":
        "original_coattention_rgb":
            "pretrained_params": "./pretrained/co_attention.pth" # './pretrained/davis_480x854_Aug16.pth' #  "./snapshots/sbmrgbd/ori/H480W640/20210907_154910/snapshot_sbmrgbd_29.pth" #"./pretrained/co_attention.pth" # './pretrained/davis_480x854_Aug16.pth'
        "original_coattention_rgb_retrained":
            "pretrained_params": "./snapshots/davis/origin/H480W854/20210823_110140/co_attention_davis_29.pth" # "./pretrained/davis_480x854_Aug16.pth"
        "refactored_coattention_rgb":
            "pretrained_params": "./snapshots/davis_480x854s/co_attention_davis_29.pth"
        "added_depth_rgbd":
            "pretrained_params": "./snapshots/sbmrgbd/add/H480W640/20210917_145359/snapshot_sbmrgbd_29.pth" # "./snapshots/hzfurgbd_iteration/H480W640/20210816_2309/snapshot_hzfurgbd_29.pth" #'./snapshots/hzfurgbd_iteration/H480W640/20210816_2309/snapshot_hzfurgbd_29.pth' #'./snapshots/hzfurgbd_iteration/H120W160/20210814_2145/co_attention_rgbd_hzfurgbd_29.pth' # './snapshots/hzfurgbd_iteration/co_attention_rgbd_hzfurgbd_29.pth' # './snapshots/co_attention_rgbd_hzfurgbd_29.pth' #'./your_path.pth' #resnet50-19c8e357.pth''/home/xiankai/PSPNet_PyTorch/snapshots/davis/psp_davis_0.pth' 
        "convs_depth_addition":
            "pretrained_params": "./snapshots/sbmrgbd/conv_add/H480W640/20210920_232012/snapshot_sbmrgbd_49.pth" #"./snapshots/sbmrgbd/conv_add/H480W640/20210919_152755/snapshot_sbmrgbd_58.pth"
        "post_added_depth_rgbd":
            "pretrained_params": "./snapshots/hzfurgbd/padd/H480W640/20210824_225825/snapshot_hzfurgbd_29.pth" #'./snapshots/hzfurgbd_iteration/H480W640/20210816_2309/snapshot_hzfurgbd_29.pth' #'./snapshots/hzfurgbd_iteration/H120W160/20210814_2145/co_attention_rgbd_hzfurgbd_29.pth' # './snapshots/hzfurgbd_iteration/co_attention_rgbd_hzfurgbd_29.pth' # './snapshots/co_attention_rgbd_hzfurgbd_29.pth' #'./your_path.pth' #resnet50-19c8e357.pth''/home/xiankai/PSPNet_PyTorch/snapshots/davis/psp_davis_0.pth'
        "concatenated_depth_rgbd":
            "pretrained_params": "./snapshots/hzfurgbd/coc/H480W640/20210822_113019/snapshot_hzfurgbd_29.pth" #20210822_164649
        "concatenated_depth_rgbd2":
            "pretrained_params": "./snapshots/hzfurgbd/conc2/H480W640/20210824_121853/snapshot_hzfurgbd_29.pth" #20210824_121853
    "dataset":
        "davis":
            "model":
            "subset_file": "/vol/graphics-solar/fengwenb/vos/dataset/DAVIS/ImageSets/480p/val.txt"
            "path": ""
            "output_WH": ""
        "hzfud":
            "model":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset"
            "output_WH": "640,480"
            "image_HW_4_model": "480, 640"
            "sample_range": 1
            "subset":
                "child_no1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png"]
                "dog_no_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png"]
                "toy_wg_occ": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png","46_obj_1.png","51_obj_1.png"]
                "tracking4": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png"]
                "zcup_move_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png"]
        "hzfurgb":
            "model":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset"
            "output_WH": "640,480"
            "image_HW_4_model": "480, 640"
            "sample_range": 1
            "subset":
                "child_no1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png"]
                "dog_no_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png"]
                "toy_wg_occ": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png","46_obj_1.png","51_obj_1.png"]
                "tracking4": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png"]
                "zcup_move_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png"]

        "hzfurgbd":
            "model":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/RGBD_video_seg_dataset"
            "output_WH": "640,480"
            "image_HW_4_model": "480, 640"
            "sample_range": 1
            "subset":
                "child_no1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png"]
                "dog_no_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png"]
                "toy_wg_occ": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png","41_obj_1.png","46_obj_1.png","51_obj_1.png"]
                "tracking4": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png","36_obj_1.png"]
                "zcup_move_1": ["01_obj_1.png","06_obj_1.png","11_obj_1.png","16_obj_1.png","21_obj_1.png","26_obj_1.png","31_obj_1.png"]

        "sbmrgbd":
            "model":
            "data_path": "/vol/graphics-solar/fengwenb/vos/dataset/sbm-rgbd/AllSequences"
            "output_WH": "640,480"
            "image_HW_4_model": "480, 640"
            "sample_range": 1
            "subset": None

